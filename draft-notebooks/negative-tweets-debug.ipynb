{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identifying Negative Sentiment in Tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Problem\n",
    "\n",
    "Google is seeking to increase Android's share of the U.S. smartphone and tablet markets.  To do so, they are seeking information on what consumers don't like about their devices.  By focusing on pain points, they hope to engineer improvements that will attract and retain more customers.\n",
    "\n",
    "While negative sentiment toward products is available in form of survey responses and customer complaints, Google also hopes to access the opinions conveyed in social media posts.  To do so, they need to identify posts which express concerns and frustrations about mobile devices from among thousands of other posts.\n",
    "\n",
    "My task is to build a model which can quickly analyze a group of posts and pinpoint those with negative sentiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Understanding\n",
    "\n",
    "To identify posts with gripes, I analyzed over 9,000 tweets from a dataset provided by Crowdflower via [data.world](https://data.world/crowdflower/brands-and-product-emotions).  The tweets all contain references to Google or Apple products, and relate to the SXSW (South by Southwest) Conference in 2011.  Although the data are a decade old, and the products discussed seem ancient (iPad 2?), the words used to convey negative emotions have not changed.  \n",
    "\n",
    "Each tweet in the dataset has been rated by humans as showing a positive emotion, negative emotion, or no emotion toward the Google or Apple product mentioned.  59% of tweets were tagged as postive and 6% as negative, making negative tweets the smallest category by far.  I combined the positive and no-emotion categories in order to build a binary classification model that can weed out all but the negative tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.float_format', lambda x: '%.5f' % x)\n",
    "pd.set_option('display.max_colwidth', 1000)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.metrics import plot_confusion_matrix, accuracy_score\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import ComplementNB, MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Input, Dense, LSTM, Embedding\n",
    "from keras.layers import Dropout, Activation, Bidirectional, GlobalMaxPool1D\n",
    "from keras.models import Sequential\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers\n",
    "from keras.preprocessing import text, sequence\n",
    "\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try to get nans out of X_train\n",
    "# find with insull\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "\n",
    "data = pd.read_csv('data/judge-1377884607_tweet_product_company.csv', encoding='latin-1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>emotion_in_tweet_is_directed_at</th>\n",
       "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs tweeting at #RISE_Austin, it was dead!  I need to upgrade. Plugin stations at #SXSW.</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/iPhone app that you'll likely appreciate for its design. Also, they're giving free Ts at #SXSW</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. They should sale them down at #SXSW.</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as crashy as this year's iPhone app. #sxsw</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa Mayer (Google), Tim O'Reilly (tech books/conferences) &amp;amp; Matt Mullenweg (Wordpress)</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>@teachntech00 New iPad Apps For #SpeechTherapy And Communication Are Showcased At The #SXSW Conference http://ht.ly/49n4M #iear #edchat #asd</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>#SXSW is just starting, #CTIA is around the corner and #googleio is only a hop skip and a jump from there, good time to be an #android fan</td>\n",
       "      <td>Android</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Beautifully smart and simple idea RT @madebymany @thenextweb wrote about our #hollergram iPad app for #sxsw! http://bit.ly/ieaVOB</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Counting down the days to #sxsw plus strong Canadian dollar means stock up on Apple gear</td>\n",
       "      <td>Apple</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Excited to meet the @samsungmobileus at #sxsw so I can show them my Sprint Galaxy S still running Android 2.1.   #fail</td>\n",
       "      <td>Android</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Find &amp;amp; Start Impromptu Parties at #SXSW With @HurricaneParty http://bit.ly/gVLrIn I can't wait til the Android app comes out.</td>\n",
       "      <td>Android App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Foursquare ups the game, just in time for #SXSW http://j.mp/grN7pK) - Still prefer @Gowalla by far, best looking Android app to date.</td>\n",
       "      <td>Android App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Gotta love this #SXSW Google Calendar featuring top parties/ show cases to check out.  RT @hamsandwich via @ischafer =&amp;gt;http://bit.ly/aXZwxB</td>\n",
       "      <td>Other Google product or service</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Great #sxsw ipad app from @madebymany: http://tinyurl.com/4nqv92l</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>haha, awesomely rad iPad app by @madebymany http://bit.ly/hTdFim #hollergram #sxsw</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Holler Gram for iPad on the iTunes App Store -  http://t.co/kfN3f5Q (via @marc_is_ken) #sxsw</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>I just noticed DST is coming this weekend. How many iPhone users will be an hour late at SXSW come Sunday morning? #SXSW #iPhone</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Just added my #SXSW flights to @planely. Matching people on planes/airports. Also downloaded the @KLM iPhone app, nicely done.</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Must have #SXSW app! RT @malbonster: Lovely review from Forbes for our SXSW iPad app Holler Gram - http://t.co/g4GZypV</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Need to buy an iPad2 while I'm in Austin at #sxsw. Not sure if I'll need to Q up at an Austin Apple store?</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Oh. My. God. The #SXSW app for iPad is pure, unadulterated awesome. It's easier to browse events on iPad than on the website!!!</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Okay, this is really it: yay new @Foursquare for #Android app!!!!11 kthxbai. #sxsw</td>\n",
       "      <td>Android App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Photo: Just installed the #SXSW iPhone app, which is really nice! http://tumblr.com/x6t1pi6av7</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Really enjoying the changes in Gowalla 3.0 for Android! Looking forward to seeing what else they &amp;amp; Foursquare have up their sleeves at #SXSW</td>\n",
       "      <td>Android App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>RT @LaurieShook: I'm looking forward to the #SMCDallas pre #SXSW party Wed., and hoping I'll win an #iPad resulting from my shameless promotion.  #ChevySMC</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>RT haha, awesomely rad iPad app by @madebymany http://bit.ly/hTdFim #hollergram #sxsw (via @michaelpiliero)</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>someone started an #austin @PartnerHub group in google groups, pre-#sxsw. great idea</td>\n",
       "      <td>Other Google product or service</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>The new #4sq3 looks like it is going to rock. Update for iPhone and Android should push tonight http://bit.ly/etsbZk #SXSW #KeepAustinWeird</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>They were right, the @gowalla 3 app on #android is sweeeeet! Nice job by the team there. #sxsw</td>\n",
       "      <td>Android App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Very smart from @madebymany #hollergram iPad app for #sxsw! http://t.co/A3xvWc6 (may leave my vuvuzela at home now)</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>You must have this app for your iPad if you are going to #SXSW http://itunes.apple.com/us/app/holler-gram/id420666439?mt=8 #hollergram</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Attn: All  #SXSW frineds, @mention Register for #GDGTLive  and see Cobra iRadar for Android. {link}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Anyone at  #sxsw want to sell their old iPad?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Anyone at  #SXSW who bought the new iPad want to sell their older iPad to me?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>At #sxsw.  Oooh. RT @mention Google to Launch Major New Social Network Called Circles, Possibly Today {link}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>The best!  RT @mention Ha! First in line for #ipad2 at #sxsw &amp;quot;pop-up&amp;quot; Apple store was an event planner #eventprofs #pcma #engage365</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>SPIN Play - a new concept in music discovery for your iPad from @mention &amp;amp; spin.com {link} #iTunes #sxsw @mention</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>@mention  - False Alarm: Google Circles Not Coming NowÛÒand Probably Not Ever? - {link} #Google #Circles #Social #SXSW</td>\n",
       "      <td>Google</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>VatorNews - Google And Apple Force Print Media to Evolve? {link} #sxsw</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>@mention  - Great weather to greet you for #sxsw! Still need a sweater at night..Apple putting up &amp;quot;flash store&amp;quot; downtown to sell iPad2</td>\n",
       "      <td>Apple</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>HootSuite - HootSuite Mobile for #SXSW ~ Updates for iPhone, BlackBerry &amp;amp; Android: Whether youÛªre getting friend... {link}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Hey #SXSW - How long do you think it takes us to make an iPhone case? answer @mention using #zazzlesxsw and weÛªll make you one!</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Mashable! - The iPad 2 Takes Over SXSW [VIDEO] #ipad #sxsw #gadgets {link}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>For I-Pad ?RT @mention New #UberSocial for #iPhone now in the App Store includes UberGuide to #SXSW sponsored by ... {link}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>#IPad2 's Û÷#SmartCoverÛª Opens to Instant Access - I should have waited to get one! - {link} #apple #SXSW</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Hand-Held Û÷HoboÛª: Drafthouse launches Û÷Hobo With a ShotgunÛª iPhone app #SXSW {link}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>HOORAY RT ÛÏ@mention Apple Is Opening A Pop-Up Store In Austin For #SXSW | @mention {link}</td>\n",
       "      <td>Apple</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Orly....? ÛÏ@mention Google set to launch new social network #Circles today at #sxswÛ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>wooooo!!! ÛÏ@mention Apple store downtown Austin open til Midnight. #sxswÛ</td>\n",
       "      <td>Apple</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Khoi Vinh (@mention says Conde Nast's headlong rush into iPad publishing was a &amp;quot;fundamental misunderstanding&amp;quot; of the platform #sxsw</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>ÛÏ@mention {link} &amp;lt;-- HELP ME FORWARD THIS DOC to all Anonymous accounts, techies,&amp;amp; ppl who can help us JAM #libya #SXSW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>÷¼ WHAT? ÷_ {link} ã_ #edchat #musedchat #sxsw #sxswi #classical #newTwitter</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>.@mention @mention on the location-based 'fast, fun and future' - {link} (via @mention #sxsw</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>ÛÏ@mention @mention #Google Will Connect the Digital &amp;amp; Physical Worlds Through Mobile - {link} #sxswÛ @mention</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>ÛÏ@mention @mention talking about {link} - Google's effort to allow users to have open systems #bettercloud #sxswÛ</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>{link} RT @mention &amp;quot;Google before you tweet&amp;quot; is the new &amp;quot;think before you speak.&amp;quot; - Mark Belinsky, #911tweets panel at #SXSW.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>{link} RT @mention 1st stop on the #SXSW #Chaos &amp;amp; @mention hunt: Austin Java. Get in the spy game 4 a chance 2 win an iPad!</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>{link} RT @mention Those at #SXSW check out the Holler Gram ipad app from @mention  {link}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>@mention  @mention &amp;amp;  @mention having fun at #google [pic] #SXSW {link}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>&amp;quot;via @mention : {link} Guy Kawasaki talks 'Enchanted' at SXSW - HE knows his stuff! #books #internet #Apple #sxsw  &amp;quot;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>#futuremf @mention {link} spec for recipes on the web, now in google search: {link}  #sxsw</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>#OMFG! RT @mention Heard about Apple's pop-up store in downtown Austin? Pics are already on Gowalla: {link} #sxsw #iPad2</td>\n",
       "      <td>Apple</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>#Smile RT @mention I think Apple's &amp;quot;pop-up store&amp;quot; in Austin would be a lot more interesting if it actually, you know... popped up #sxsw</td>\n",
       "      <td>Apple</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>Again? RT @mention Line at the Apple store is insane.. #sxsw</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>Agree. RT @mention Wait. FIONA APPLE is in town??? Somebody kidnap her and put her in a recording studio until she records a new album. #sxsw</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>At #sxsw? @mention / @mention wanna buy you a drink. 7pm at Fado on 4th. {link} Join us!</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>attending @mention iPad design headaches #sxsw {link}</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>Boooo! RT @mention Flipboard is developing an iPhone version, not Android, says @mention #sxsw</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>Check out @mention @mention &amp;amp; @mention in line for their iPad 2 in Austin. Power to them! #sxswi #SXSW  {link}</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>Check! RT @mention giving added value to location based services needs to battle check-in fatigue #google #pnid #sxsw</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>Chilcott: @mention #SXSW stand talking with Blogger staff. Too late to win competition for best tweet mentioning @mention So no t-shirt.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>Do it. RT @mention Come party w/ Google tonight at #sxsw! {link} - Bands, food, art, ice cream, nifty interactive maps!</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>Gowalla's @mention promises to launch Foursquare check-in + Groupon rewards-type service at #SXSW. Finger's crossed. {link}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>Ha.ha. RT @mention #SXSW News: Yahoo.com is loosing search traffic to new site, Google.com. Doubt it will last tho w/ that weird name.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>Holla! RT @mention At google party. Best ever! Get your butt over here. #sxsw</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>I love my @mention iPhone case from #Sxsw but I can't get my phone out of it #fail</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>I worship @mention {link} #SXSW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>iPad2? RT @mention Droid &amp;amp; Mac here :) RT @mention My #agnerd confession, using laptop, iPad &amp;amp; blackberry to follow #SXSW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>Launching @mention #SxSW? RT @mention @mention Denies Social Network Called Circles Will Debut Today, Despite Report {link}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>New Post: @mention iPhone app makes it easy to connect on all social networks with people you meet  {link} #sxsw</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>Nice that @mention iPhone app is behaving today. Crashes yesterday were ridiculous. #sxsw</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>Nice!  RT @mention Apple opening popup store for iPad launch in downtown Austin during #SXSW {link} via @mention</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>Nice!! RT @mention Hey, Apple fans! Get a peek at the space that's slated to be a pop-up #SXSW Apple Store tomorrow: {link}</td>\n",
       "      <td>Apple</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>one thing @mention is doing so great is get a great, down to earth face to Google as a company - You can only love her #sxsw #sxwsi</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>Stay tune @mention showcase #H4ckers {link} #SXSW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>Thank you @mention @mention for the #touchingstories preso #SXSW . Here's their deck {link}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>Thank you @mention for an awesome #sxsw party! {link}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>Thanks RT @mention If you're trying to contact friends or family in #Japan, @mention has created a person finder: {link} #SXSW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>Thanks to @mention for her mention of our new #Speech iPad apps being showcased at the #SXSW Conf. {link} #sxswh #sxsh</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>Thanks to @mention for publishing the news of @mention new medical Apps at the #sxswi conf. blog {link} #sxsw #sxswh</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I can't tell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>Thanks to @mention for publishing the news of our new medical Apps in the #sxswi conf. blog {link} #sxsw #sxswh #mhealth</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>What !?!? @mention  #SXSW does not provide iPhone chargers?!?  I've changed my mind about going next year!</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>Wonder if @mention &amp;amp; @mention will be in the apple flashmob: tcrn.ch/fcs45j #SXSW #ipad2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>Wonder if @mention is putting tips from the @mention API... #SxSW #SUxSW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>XMAS!! RT @mention Shiny new @mention @mention @mention apps, a new @garyvee book, pop-up iPad 2 stores... #SXSW is Christmas for nerds.</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Yai!!! RT @mention New #UberSocial for #iPhone now in the App Store includes UberGuide to #SXSW sponsored by (cont) {link}</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Yes!!! RT @mention hey @mention , i've got another gem for you --&amp;gt; free @mention sxsw {link} #SXSW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Fast, Fun &amp;amp; Future: @mention of Google presenting at #sxsw on search, local and mobile</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>GSD&amp;amp;M &amp;amp; Google's Industry Party Tonight @mention - See u there! {link} #SXSW #Austin #Welivehere #GSDM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                     tweet_text  \\\n",
       "0                               .@wesley83 I have a 3G iPhone. After 3 hrs tweeting at #RISE_Austin, it was dead!  I need to upgrade. Plugin stations at #SXSW.   \n",
       "1                   @jessedee Know about @fludapp ? Awesome iPad/iPhone app that you'll likely appreciate for its design. Also, they're giving free Ts at #SXSW   \n",
       "2                                                                               @swonderlin Can not wait for #iPad 2 also. They should sale them down at #SXSW.   \n",
       "3                                                                            @sxsw I hope this year's festival isn't as crashy as this year's iPhone app. #sxsw   \n",
       "4                           @sxtxstate great stuff on Fri #SXSW: Marissa Mayer (Google), Tim O'Reilly (tech books/conferences) &amp; Matt Mullenweg (Wordpress)   \n",
       "5                  @teachntech00 New iPad Apps For #SpeechTherapy And Communication Are Showcased At The #SXSW Conference http://ht.ly/49n4M #iear #edchat #asd   \n",
       "6                                                                                                                                                           NaN   \n",
       "7                    #SXSW is just starting, #CTIA is around the corner and #googleio is only a hop skip and a jump from there, good time to be an #android fan   \n",
       "8                             Beautifully smart and simple idea RT @madebymany @thenextweb wrote about our #hollergram iPad app for #sxsw! http://bit.ly/ieaVOB   \n",
       "9                                                                      Counting down the days to #sxsw plus strong Canadian dollar means stock up on Apple gear   \n",
       "10                                       Excited to meet the @samsungmobileus at #sxsw so I can show them my Sprint Galaxy S still running Android 2.1.   #fail   \n",
       "11                            Find &amp; Start Impromptu Parties at #SXSW With @HurricaneParty http://bit.ly/gVLrIn I can't wait til the Android app comes out.   \n",
       "12                        Foursquare ups the game, just in time for #SXSW http://j.mp/grN7pK) - Still prefer @Gowalla by far, best looking Android app to date.   \n",
       "13               Gotta love this #SXSW Google Calendar featuring top parties/ show cases to check out.  RT @hamsandwich via @ischafer =&gt;http://bit.ly/aXZwxB   \n",
       "14                                                                                            Great #sxsw ipad app from @madebymany: http://tinyurl.com/4nqv92l   \n",
       "15                                                                           haha, awesomely rad iPad app by @madebymany http://bit.ly/hTdFim #hollergram #sxsw   \n",
       "16                                                                 Holler Gram for iPad on the iTunes App Store -  http://t.co/kfN3f5Q (via @marc_is_ken) #sxsw   \n",
       "17                             I just noticed DST is coming this weekend. How many iPhone users will be an hour late at SXSW come Sunday morning? #SXSW #iPhone   \n",
       "18                               Just added my #SXSW flights to @planely. Matching people on planes/airports. Also downloaded the @KLM iPhone app, nicely done.   \n",
       "19                                       Must have #SXSW app! RT @malbonster: Lovely review from Forbes for our SXSW iPad app Holler Gram - http://t.co/g4GZypV   \n",
       "20                                                   Need to buy an iPad2 while I'm in Austin at #sxsw. Not sure if I'll need to Q up at an Austin Apple store?   \n",
       "21                              Oh. My. God. The #SXSW app for iPad is pure, unadulterated awesome. It's easier to browse events on iPad than on the website!!!   \n",
       "22                                                                           Okay, this is really it: yay new @Foursquare for #Android app!!!!11 kthxbai. #sxsw   \n",
       "23                                                               Photo: Just installed the #SXSW iPhone app, which is really nice! http://tumblr.com/x6t1pi6av7   \n",
       "24             Really enjoying the changes in Gowalla 3.0 for Android! Looking forward to seeing what else they &amp; Foursquare have up their sleeves at #SXSW   \n",
       "25  RT @LaurieShook: I'm looking forward to the #SMCDallas pre #SXSW party Wed., and hoping I'll win an #iPad resulting from my shameless promotion.  #ChevySMC   \n",
       "26                                                  RT haha, awesomely rad iPad app by @madebymany http://bit.ly/hTdFim #hollergram #sxsw (via @michaelpiliero)   \n",
       "27                                                                         someone started an #austin @PartnerHub group in google groups, pre-#sxsw. great idea   \n",
       "28                  The new #4sq3 looks like it is going to rock. Update for iPhone and Android should push tonight http://bit.ly/etsbZk #SXSW #KeepAustinWeird   \n",
       "29                                                               They were right, the @gowalla 3 app on #android is sweeeeet! Nice job by the team there. #sxsw   \n",
       "30                                          Very smart from @madebymany #hollergram iPad app for #sxsw! http://t.co/A3xvWc6 (may leave my vuvuzela at home now)   \n",
       "31                       You must have this app for your iPad if you are going to #SXSW http://itunes.apple.com/us/app/holler-gram/id420666439?mt=8 #hollergram   \n",
       "32                                                          Attn: All  #SXSW frineds, @mention Register for #GDGTLive  and see Cobra iRadar for Android. {link}   \n",
       "33                                                                                                                Anyone at  #sxsw want to sell their old iPad?   \n",
       "34                                                                                Anyone at  #SXSW who bought the new iPad want to sell their older iPad to me?   \n",
       "35                                                 At #sxsw.  Oooh. RT @mention Google to Launch Major New Social Network Called Circles, Possibly Today {link}   \n",
       "36                The best!  RT @mention Ha! First in line for #ipad2 at #sxsw &quot;pop-up&quot; Apple store was an event planner #eventprofs #pcma #engage365   \n",
       "37                                        SPIN Play - a new concept in music discovery for your iPad from @mention &amp; spin.com {link} #iTunes #sxsw @mention   \n",
       "38                                      @mention  - False Alarm: Google Circles Not Coming NowÛÒand Probably Not Ever? - {link} #Google #Circles #Social #SXSW   \n",
       "39                                                                                       VatorNews - Google And Apple Force Print Media to Evolve? {link} #sxsw   \n",
       "40             @mention  - Great weather to greet you for #sxsw! Still need a sweater at night..Apple putting up &quot;flash store&quot; downtown to sell iPad2   \n",
       "41                             HootSuite - HootSuite Mobile for #SXSW ~ Updates for iPhone, BlackBerry &amp; Android: Whether youÛªre getting friend... {link}   \n",
       "42                            Hey #SXSW - How long do you think it takes us to make an iPhone case? answer @mention using #zazzlesxsw and weÛªll make you one!   \n",
       "43                                                                                   Mashable! - The iPad 2 Takes Over SXSW [VIDEO] #ipad #sxsw #gadgets {link}   \n",
       "44                                  For I-Pad ?RT @mention New #UberSocial for #iPhone now in the App Store includes UberGuide to #SXSW sponsored by ... {link}   \n",
       "45                                                 #IPad2 's Û÷#SmartCoverÛª Opens to Instant Access - I should have waited to get one! - {link} #apple #SXSW   \n",
       "46                                                                  Hand-Held Û÷HoboÛª: Drafthouse launches Û÷Hobo With a ShotgunÛª iPhone app #SXSW {link}   \n",
       "47                                                                  HOORAY RT ÛÏ@mention Apple Is Opening A Pop-Up Store In Austin For #SXSW | @mention {link}   \n",
       "48                                                                     Orly....? ÛÏ@mention Google set to launch new social network #Circles today at #sxswÛ   \n",
       "49                                                                                wooooo!!! ÛÏ@mention Apple store downtown Austin open til Midnight. #sxswÛ   \n",
       "50                Khoi Vinh (@mention says Conde Nast's headlong rush into iPad publishing was a &quot;fundamental misunderstanding&quot; of the platform #sxsw   \n",
       "51                             ÛÏ@mention {link} &lt;-- HELP ME FORWARD THIS DOC to all Anonymous accounts, techies,&amp; ppl who can help us JAM #libya #SXSW   \n",
       "52                                                                              ÷¼ WHAT? ÷_ {link} ã_ #edchat #musedchat #sxsw #sxswi #classical #newTwitter   \n",
       "53                                                                 .@mention @mention on the location-based 'fast, fun and future' - {link} (via @mention #sxsw   \n",
       "54                                        ÛÏ@mention @mention #Google Will Connect the Digital &amp; Physical Worlds Through Mobile - {link} #sxswÛ @mention   \n",
       "55                                        ÛÏ@mention @mention talking about {link} - Google's effort to allow users to have open systems #bettercloud #sxswÛ   \n",
       "56            {link} RT @mention &quot;Google before you tweet&quot; is the new &quot;think before you speak.&quot; - Mark Belinsky, #911tweets panel at #SXSW.   \n",
       "57                              {link} RT @mention 1st stop on the #SXSW #Chaos &amp; @mention hunt: Austin Java. Get in the spy game 4 a chance 2 win an iPad!   \n",
       "58                                                                   {link} RT @mention Those at #SXSW check out the Holler Gram ipad app from @mention  {link}   \n",
       "59                                                                                  @mention  @mention &amp;  @mention having fun at #google [pic] #SXSW {link}   \n",
       "60                               &quot;via @mention : {link} Guy Kawasaki talks 'Enchanted' at SXSW - HE knows his stuff! #books #internet #Apple #sxsw  &quot;   \n",
       "61                                                                   #futuremf @mention {link} spec for recipes on the web, now in google search: {link}  #sxsw   \n",
       "62                                     #OMFG! RT @mention Heard about Apple's pop-up store in downtown Austin? Pics are already on Gowalla: {link} #sxsw #iPad2   \n",
       "63            #Smile RT @mention I think Apple's &quot;pop-up store&quot; in Austin would be a lot more interesting if it actually, you know... popped up #sxsw   \n",
       "64                                                                                                 Again? RT @mention Line at the Apple store is insane.. #sxsw   \n",
       "65                Agree. RT @mention Wait. FIONA APPLE is in town??? Somebody kidnap her and put her in a recording studio until she records a new album. #sxsw   \n",
       "66                                                                     At #sxsw? @mention / @mention wanna buy you a drink. 7pm at Fado on 4th. {link} Join us!   \n",
       "67                                                                                                        attending @mention iPad design headaches #sxsw {link}   \n",
       "68                                                               Boooo! RT @mention Flipboard is developing an iPhone version, not Android, says @mention #sxsw   \n",
       "69                                           Check out @mention @mention &amp; @mention in line for their iPad 2 in Austin. Power to them! #sxswi #SXSW  {link}   \n",
       "70                                        Check! RT @mention giving added value to location based services needs to battle check-in fatigue #google #pnid #sxsw   \n",
       "71                     Chilcott: @mention #SXSW stand talking with Blogger staff. Too late to win competition for best tweet mentioning @mention So no t-shirt.   \n",
       "72                                      Do it. RT @mention Come party w/ Google tonight at #sxsw! {link} - Bands, food, art, ice cream, nifty interactive maps!   \n",
       "73                                  Gowalla's @mention promises to launch Foursquare check-in + Groupon rewards-type service at #SXSW. Finger's crossed. {link}   \n",
       "74                       Ha.ha. RT @mention #SXSW News: Yahoo.com is loosing search traffic to new site, Google.com. Doubt it will last tho w/ that weird name.   \n",
       "75                                                                                Holla! RT @mention At google party. Best ever! Get your butt over here. #sxsw   \n",
       "76                                                                           I love my @mention iPhone case from #Sxsw but I can't get my phone out of it #fail   \n",
       "77                                                                                                                              I worship @mention {link} #SXSW   \n",
       "78                            iPad2? RT @mention Droid &amp; Mac here :) RT @mention My #agnerd confession, using laptop, iPad &amp; blackberry to follow #SXSW   \n",
       "79                                  Launching @mention #SxSW? RT @mention @mention Denies Social Network Called Circles Will Debut Today, Despite Report {link}   \n",
       "80                                             New Post: @mention iPhone app makes it easy to connect on all social networks with people you meet  {link} #sxsw   \n",
       "81                                                                    Nice that @mention iPhone app is behaving today. Crashes yesterday were ridiculous. #sxsw   \n",
       "82                                             Nice!  RT @mention Apple opening popup store for iPad launch in downtown Austin during #SXSW {link} via @mention   \n",
       "83                                  Nice!! RT @mention Hey, Apple fans! Get a peek at the space that's slated to be a pop-up #SXSW Apple Store tomorrow: {link}   \n",
       "84                          one thing @mention is doing so great is get a great, down to earth face to Google as a company - You can only love her #sxsw #sxwsi   \n",
       "85                                                                                                            Stay tune @mention showcase #H4ckers {link} #SXSW   \n",
       "86                                                                  Thank you @mention @mention for the #touchingstories preso #SXSW . Here's their deck {link}   \n",
       "87                                                                                                        Thank you @mention for an awesome #sxsw party! {link}   \n",
       "88                               Thanks RT @mention If you're trying to contact friends or family in #Japan, @mention has created a person finder: {link} #SXSW   \n",
       "89                                       Thanks to @mention for her mention of our new #Speech iPad apps being showcased at the #SXSW Conf. {link} #sxswh #sxsh   \n",
       "90                                         Thanks to @mention for publishing the news of @mention new medical Apps at the #sxswi conf. blog {link} #sxsw #sxswh   \n",
       "91                                     Thanks to @mention for publishing the news of our new medical Apps in the #sxswi conf. blog {link} #sxsw #sxswh #mhealth   \n",
       "92                                                   What !?!? @mention  #SXSW does not provide iPhone chargers?!?  I've changed my mind about going next year!   \n",
       "93                                                                 Wonder if @mention &amp; @mention will be in the apple flashmob: tcrn.ch/fcs45j #SXSW #ipad2   \n",
       "94                                                                                     Wonder if @mention is putting tips from the @mention API... #SxSW #SUxSW   \n",
       "95                     XMAS!! RT @mention Shiny new @mention @mention @mention apps, a new @garyvee book, pop-up iPad 2 stores... #SXSW is Christmas for nerds.   \n",
       "96                                   Yai!!! RT @mention New #UberSocial for #iPhone now in the App Store includes UberGuide to #SXSW sponsored by (cont) {link}   \n",
       "97                                                        Yes!!! RT @mention hey @mention , i've got another gem for you --&gt; free @mention sxsw {link} #SXSW   \n",
       "98                                                                   Fast, Fun &amp; Future: @mention of Google presenting at #sxsw on search, local and mobile   \n",
       "99                                               GSD&amp;M &amp; Google's Industry Party Tonight @mention - See u there! {link} #SXSW #Austin #Welivehere #GSDM   \n",
       "\n",
       "    emotion_in_tweet_is_directed_at  \\\n",
       "0                            iPhone   \n",
       "1                iPad or iPhone App   \n",
       "2                              iPad   \n",
       "3                iPad or iPhone App   \n",
       "4                            Google   \n",
       "5                               NaN   \n",
       "6                               NaN   \n",
       "7                           Android   \n",
       "8                iPad or iPhone App   \n",
       "9                             Apple   \n",
       "10                          Android   \n",
       "11                      Android App   \n",
       "12                      Android App   \n",
       "13  Other Google product or service   \n",
       "14               iPad or iPhone App   \n",
       "15               iPad or iPhone App   \n",
       "16                              NaN   \n",
       "17                           iPhone   \n",
       "18               iPad or iPhone App   \n",
       "19               iPad or iPhone App   \n",
       "20                             iPad   \n",
       "21               iPad or iPhone App   \n",
       "22                      Android App   \n",
       "23               iPad or iPhone App   \n",
       "24                      Android App   \n",
       "25                             iPad   \n",
       "26               iPad or iPhone App   \n",
       "27  Other Google product or service   \n",
       "28               iPad or iPhone App   \n",
       "29                      Android App   \n",
       "30               iPad or iPhone App   \n",
       "31               iPad or iPhone App   \n",
       "32                              NaN   \n",
       "33                              NaN   \n",
       "34                              NaN   \n",
       "35                              NaN   \n",
       "36                             iPad   \n",
       "37                              NaN   \n",
       "38                           Google   \n",
       "39                              NaN   \n",
       "40                            Apple   \n",
       "41                              NaN   \n",
       "42                              NaN   \n",
       "43                              NaN   \n",
       "44                              NaN   \n",
       "45               iPad or iPhone App   \n",
       "46                              NaN   \n",
       "47                            Apple   \n",
       "48                              NaN   \n",
       "49                            Apple   \n",
       "50                              NaN   \n",
       "51                              NaN   \n",
       "52                              NaN   \n",
       "53                              NaN   \n",
       "54                              NaN   \n",
       "55                           Google   \n",
       "56                              NaN   \n",
       "57                             iPad   \n",
       "58                              NaN   \n",
       "59                              NaN   \n",
       "60                              NaN   \n",
       "61                              NaN   \n",
       "62                            Apple   \n",
       "63                            Apple   \n",
       "64                              NaN   \n",
       "65                              NaN   \n",
       "66                              NaN   \n",
       "67                             iPad   \n",
       "68                              NaN   \n",
       "69                             iPad   \n",
       "70                              NaN   \n",
       "71                              NaN   \n",
       "72                           Google   \n",
       "73                              NaN   \n",
       "74                              NaN   \n",
       "75                           Google   \n",
       "76                           iPhone   \n",
       "77                              NaN   \n",
       "78                              NaN   \n",
       "79                              NaN   \n",
       "80               iPad or iPhone App   \n",
       "81               iPad or iPhone App   \n",
       "82                              NaN   \n",
       "83                            Apple   \n",
       "84                           Google   \n",
       "85                              NaN   \n",
       "86                              NaN   \n",
       "87                              NaN   \n",
       "88                              NaN   \n",
       "89               iPad or iPhone App   \n",
       "90                              NaN   \n",
       "91                              NaN   \n",
       "92                           iPhone   \n",
       "93                              NaN   \n",
       "94                              NaN   \n",
       "95                             iPad   \n",
       "96                           iPhone   \n",
       "97                              NaN   \n",
       "98                           Google   \n",
       "99                              NaN   \n",
       "\n",
       "   is_there_an_emotion_directed_at_a_brand_or_product  \n",
       "0                                    Negative emotion  \n",
       "1                                    Positive emotion  \n",
       "2                                    Positive emotion  \n",
       "3                                    Negative emotion  \n",
       "4                                    Positive emotion  \n",
       "5                  No emotion toward brand or product  \n",
       "6                  No emotion toward brand or product  \n",
       "7                                    Positive emotion  \n",
       "8                                    Positive emotion  \n",
       "9                                    Positive emotion  \n",
       "10                                   Positive emotion  \n",
       "11                                   Positive emotion  \n",
       "12                                   Positive emotion  \n",
       "13                                   Positive emotion  \n",
       "14                                   Positive emotion  \n",
       "15                                   Positive emotion  \n",
       "16                 No emotion toward brand or product  \n",
       "17                                   Negative emotion  \n",
       "18                                   Positive emotion  \n",
       "19                                   Positive emotion  \n",
       "20                                   Positive emotion  \n",
       "21                                   Positive emotion  \n",
       "22                                   Positive emotion  \n",
       "23                                   Positive emotion  \n",
       "24                                   Positive emotion  \n",
       "25                                   Positive emotion  \n",
       "26                                   Positive emotion  \n",
       "27                                   Positive emotion  \n",
       "28                                   Positive emotion  \n",
       "29                                   Positive emotion  \n",
       "30                                   Positive emotion  \n",
       "31                                   Positive emotion  \n",
       "32                 No emotion toward brand or product  \n",
       "33                 No emotion toward brand or product  \n",
       "34                 No emotion toward brand or product  \n",
       "35                 No emotion toward brand or product  \n",
       "36                                   Positive emotion  \n",
       "37                 No emotion toward brand or product  \n",
       "38                                   Negative emotion  \n",
       "39                 No emotion toward brand or product  \n",
       "40                                   Positive emotion  \n",
       "41                 No emotion toward brand or product  \n",
       "42                 No emotion toward brand or product  \n",
       "43                 No emotion toward brand or product  \n",
       "44                 No emotion toward brand or product  \n",
       "45                                   Positive emotion  \n",
       "46                                   Positive emotion  \n",
       "47                                   Positive emotion  \n",
       "48                 No emotion toward brand or product  \n",
       "49                                   Positive emotion  \n",
       "50                 No emotion toward brand or product  \n",
       "51                 No emotion toward brand or product  \n",
       "52                 No emotion toward brand or product  \n",
       "53                 No emotion toward brand or product  \n",
       "54                 No emotion toward brand or product  \n",
       "55                                   Positive emotion  \n",
       "56                 No emotion toward brand or product  \n",
       "57                                   Positive emotion  \n",
       "58                 No emotion toward brand or product  \n",
       "59                 No emotion toward brand or product  \n",
       "60                 No emotion toward brand or product  \n",
       "61                 No emotion toward brand or product  \n",
       "62                                   Positive emotion  \n",
       "63                 No emotion toward brand or product  \n",
       "64                                   Negative emotion  \n",
       "65                 No emotion toward brand or product  \n",
       "66                 No emotion toward brand or product  \n",
       "67                                   Negative emotion  \n",
       "68                                   Negative emotion  \n",
       "69                                   Positive emotion  \n",
       "70                 No emotion toward brand or product  \n",
       "71                 No emotion toward brand or product  \n",
       "72                                   Positive emotion  \n",
       "73                 No emotion toward brand or product  \n",
       "74                 No emotion toward brand or product  \n",
       "75                                   Positive emotion  \n",
       "76                                   Positive emotion  \n",
       "77                 No emotion toward brand or product  \n",
       "78                 No emotion toward brand or product  \n",
       "79                 No emotion toward brand or product  \n",
       "80                                   Positive emotion  \n",
       "81                                   Positive emotion  \n",
       "82                 No emotion toward brand or product  \n",
       "83                                   Positive emotion  \n",
       "84                                   Positive emotion  \n",
       "85                 No emotion toward brand or product  \n",
       "86                 No emotion toward brand or product  \n",
       "87                 No emotion toward brand or product  \n",
       "88                 No emotion toward brand or product  \n",
       "89                                   Positive emotion  \n",
       "90                                       I can't tell  \n",
       "91                 No emotion toward brand or product  \n",
       "92                                   Negative emotion  \n",
       "93                 No emotion toward brand or product  \n",
       "94                 No emotion toward brand or product  \n",
       "95                                   Positive emotion  \n",
       "96                                   Positive emotion  \n",
       "97                 No emotion toward brand or product  \n",
       "98                                   Positive emotion  \n",
       "99                 No emotion toward brand or product  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9093"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shorten column names\n",
    "\n",
    "data.rename(columns={'tweet_text':'text', 'is_there_an_emotion_directed_at_a_brand_or_product': 'label'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop this column since this model will only predict sentiment, not the product as well\n",
    "\n",
    "data.drop(columns = 'emotion_in_tweet_is_directed_at', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text     1\n",
       "label    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one null value\n",
    "\n",
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs tweeting at #RISE_Austin, it was dead!  I need to upgrade. Plugin stations at #SXSW.</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/iPhone app that you'll likely appreciate for its design. Also, they're giving free Ts at #SXSW</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. They should sale them down at #SXSW.</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as crashy as this year's iPhone app. #sxsw</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa Mayer (Google), Tim O'Reilly (tech books/conferences) &amp;amp; Matt Mullenweg (Wordpress)</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9088</th>\n",
       "      <td>Ipad everywhere. #SXSW {link}</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9089</th>\n",
       "      <td>Wave, buzz... RT @mention We interrupt your regularly scheduled #sxsw geek programming with big news {link}  #google #circles</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9090</th>\n",
       "      <td>Google's Zeiger, a physician never reported potential AE. Yet FDA relies on physicians. &amp;quot;We're operating w/out data.&amp;quot; #sxsw #health2dev</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9091</th>\n",
       "      <td>Some Verizon iPhone customers complained their time fell back an hour this weekend.  Of course they were the New Yorkers who attended #SXSW.</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9092</th>\n",
       "      <td>Ï¡Ïàü_ÊÎÒ£Áââ_£â_ÛâRT @mention Google Tests ÛÏCheck-in OffersÛ At #SXSW {link}</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9092 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                   text  \\\n",
       "0                       .@wesley83 I have a 3G iPhone. After 3 hrs tweeting at #RISE_Austin, it was dead!  I need to upgrade. Plugin stations at #SXSW.   \n",
       "1           @jessedee Know about @fludapp ? Awesome iPad/iPhone app that you'll likely appreciate for its design. Also, they're giving free Ts at #SXSW   \n",
       "2                                                                       @swonderlin Can not wait for #iPad 2 also. They should sale them down at #SXSW.   \n",
       "3                                                                    @sxsw I hope this year's festival isn't as crashy as this year's iPhone app. #sxsw   \n",
       "4                   @sxtxstate great stuff on Fri #SXSW: Marissa Mayer (Google), Tim O'Reilly (tech books/conferences) &amp; Matt Mullenweg (Wordpress)   \n",
       "...                                                                                                                                                 ...   \n",
       "9088                                                                                                                      Ipad everywhere. #SXSW {link}   \n",
       "9089                      Wave, buzz... RT @mention We interrupt your regularly scheduled #sxsw geek programming with big news {link}  #google #circles   \n",
       "9090  Google's Zeiger, a physician never reported potential AE. Yet FDA relies on physicians. &quot;We're operating w/out data.&quot; #sxsw #health2dev   \n",
       "9091       Some Verizon iPhone customers complained their time fell back an hour this weekend.  Of course they were the New Yorkers who attended #SXSW.   \n",
       "9092                                           Ï¡Ïàü_ÊÎÒ£Áââ_£â_ÛâRT @mention Google Tests ÛÏCheck-in OffersÛ At #SXSW {link}   \n",
       "\n",
       "                                   label  \n",
       "0                       Negative emotion  \n",
       "1                       Positive emotion  \n",
       "2                       Positive emotion  \n",
       "3                       Negative emotion  \n",
       "4                       Positive emotion  \n",
       "...                                  ...  \n",
       "9088                    Positive emotion  \n",
       "9089  No emotion toward brand or product  \n",
       "9090  No emotion toward brand or product  \n",
       "9091  No emotion toward brand or product  \n",
       "9092  No emotion toward brand or product  \n",
       "\n",
       "[9092 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No emotion toward brand or product   0.59261\n",
       "Positive emotion                     0.32754\n",
       "Negative emotion                     0.06269\n",
       "I can't tell                         0.01716\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check out label distribution\n",
    "\n",
    "data['label'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine \"No emotion toward brand or product\", \"I can't tell\", and \"Positive emotion\"\n",
    "# since the goal is to find negative tweets\n",
    "# shorten combined label name to \"No emotion\"\n",
    "\n",
    "data['label'] = data['label'].map(lambda x: 'Not negative' if x != \"Negative emotion\"\n",
    "                                 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Not negative       0.93731\n",
       "Negative emotion   0.06269\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check out new label distribution\n",
    "\n",
    "data['label'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create stopwords list\n",
    "\n",
    "stopwords_list = stopwords.words('english')\n",
    "stopwords_list += string.punctuation\n",
    "stopwords_list += ['sxsw','mention','rt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " '!',\n",
       " '\"',\n",
       " '#',\n",
       " '$',\n",
       " '%',\n",
       " '&',\n",
       " \"'\",\n",
       " '(',\n",
       " ')',\n",
       " '*',\n",
       " '+',\n",
       " ',',\n",
       " '-',\n",
       " '.',\n",
       " '/',\n",
       " ':',\n",
       " ';',\n",
       " '<',\n",
       " '=',\n",
       " '>',\n",
       " '?',\n",
       " '@',\n",
       " '[',\n",
       " '\\\\',\n",
       " ']',\n",
       " '^',\n",
       " '_',\n",
       " '`',\n",
       " '{',\n",
       " '|',\n",
       " '}',\n",
       " '~',\n",
       " 'sxsw',\n",
       " 'mention',\n",
       " 'rt']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_list_2 = ['sxsw', 'mention', 'rt', 'i']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create X and y\n",
    "\n",
    "X = data['text']\n",
    "y = data['label']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reformat X to lowercase and string (some tweets were numeric)\n",
    "\n",
    "X = X.astype(str).map(lambda x: x.lower())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8637 455\n"
     ]
    }
   ],
   "source": [
    "# create holdout set\n",
    "\n",
    "X_train, X_holdout, y_train, y_holdout = train_test_split(X, y, test_size=0.05)\n",
    "\n",
    "print(len(X_train), len(X_holdout))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype(str).map(lambda x: x.lower())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'countvec' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-b5c33ea35f5e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpredictor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mvectorizer\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mcountvec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mnb_count\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'countvec' is not defined"
     ]
    }
   ],
   "source": [
    "predictor=X_train\n",
    "target=y_train\n",
    "vectorizer= countvec\n",
    "classifier= nb_count\n",
    "\n",
    "kf = KFold(n_splits=5)\n",
    "vec = vectorizer\n",
    "clf = classifier\n",
    "\n",
    "train_recall_scores = []\n",
    "train_precision_scores = []\n",
    "train_f1_scores = []\n",
    "test_recall_scores = []\n",
    "test_precision_scores = []\n",
    "test_f1_scores = []\n",
    "\n",
    "for train_index, test_index in kf.split(predictor):\n",
    "    X_tr, X_test = predictor[train_index], predictor[test_index]\n",
    "    y_tr, y_test = target[train_index], target[test_index]\n",
    "\n",
    "    X_tr = X_tr.astype(str)\n",
    "    X_test = X_test.astype(str)\n",
    "\n",
    "    X_vec_tr = vec.fit_transform(X_tr)\n",
    "    X_vec_test = vec.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-f1925c018cf1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'X_test' is not defined"
     ]
    }
   ],
   "source": [
    "X_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_vec_tr = vec.fit_transform(X_tr)\n",
    "\n",
    "X_vec_test = vec.transform(X_test)\n",
    "\n",
    "clf.fit(X_vec_tr, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function works when I use X and y as inputs, but not X_train and y_train\n",
    "# X_tr and X_test have nans, but I don't know why\n",
    "\n",
    "def k_fold_validator(predictor, target, vectorizer, classifier, cv=5):\n",
    "\n",
    "    kf = KFold(n_splits=cv)\n",
    "    vec = vectorizer\n",
    "    clf = classifier\n",
    "\n",
    "    train_recall_scores = []\n",
    "    train_precision_scores = []\n",
    "    train_f1_scores = []\n",
    "    test_recall_scores = []\n",
    "    test_precision_scores = []\n",
    "    test_f1_scores = []\n",
    "    \n",
    "    print('Vectorizer:', vectorizer)\n",
    "    print('Classifier:', clf)\n",
    "    print('Cross-validation folds:', cv)\n",
    "    \n",
    "    for train_index, test_index in kf.split(predictor):\n",
    "\n",
    "        X_tr, X_test = predictor[train_index], predictor[test_index]\n",
    "        y_tr, y_test = target[train_index], target[test_index]\n",
    "        \n",
    "        X_tr = X_tr.astype(str)\n",
    "        X_test = X_test.astype(str)\n",
    "\n",
    "        X_vec_tr = vec.fit_transform(X_tr)\n",
    "        X_vec_test = vec.transform(X_test)\n",
    "        \n",
    "        clf.fit(X_vec_tr, y_tr)\n",
    "\n",
    "        y_pred_tr = clf.predict(X_vec_tr)\n",
    "        y_pred_test = clf.predict(X_vec_test)\n",
    "\n",
    "        train_recall_scores.append(recall_score(y_tr, y_pred_tr, pos_label='Negative emotion'))\n",
    "        train_precision_scores.append(precision_score(y_tr, y_pred_tr, pos_label='Negative emotion'))\n",
    "        train_f1_scores.append(f1_score(y_tr, y_pred_tr, pos_label='Negative emotion'))       \n",
    "        test_recall_scores.append(recall_score(y_test, y_pred_test, pos_label='Negative emotion'))\n",
    "        test_precision_scores.append(precision_score(y_test, y_pred_test, pos_label='Negative emotion'))\n",
    "        test_f1_scores.append(f1_score(y_test, y_pred_test, pos_label='Negative emotion'))       \n",
    "        \n",
    "        plot_confusion_matrix(clf, X_vec_test, y_test)\n",
    "        plt.title('Test set')\n",
    "        \n",
    "    print('Train mean recall:', round(pd.Series(train_recall_scores).mean(),2))\n",
    "    print('Train mean precision:', round(pd.Series(train_precision_scores).mean(),2))\n",
    "    print('Train mean F1:', round(pd.Series(train_f1_scores).mean(),2))\n",
    "    print('Test mean recall:', round(pd.Series(test_recall_scores).mean(),2))\n",
    "    print('Test mean precision:', round(pd.Series(test_precision_scores).mean(),2))\n",
    "    print('Test mean F1:', round(pd.Series(test_f1_scores).mean(),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create count vectorizer for testing\n",
    "\n",
    "countvec = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create Multinomial Naive Bayes model for testing\n",
    "\n",
    "nb_count = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizer: CountVectorizer()\n",
      "Classifier: MultinomialNB()\n",
      "Cross-validation folds: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/pandas/core/series.py:1146: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#deprecate-loc-reindex-listlike\n",
      "  return self.loc[key]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'<' not supported between instances of 'float' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-942ee6e5206a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mk_fold_validator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcountvec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnb_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-23-5ac0eaf5666b>\u001b[0m in \u001b[0;36mk_fold_validator\u001b[0;34m(predictor, target, vectorizer, classifier, cv)\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mtrain_precision_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprecision_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Negative emotion'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mtrain_f1_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Negative emotion'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mtest_recall_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecall_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Negative emotion'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0mtest_precision_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprecision_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Negative emotion'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mtest_f1_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Negative emotion'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mrecall_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1775\u001b[0m                                                  \u001b[0mwarn_for\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'recall'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1776\u001b[0m                                                  \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1777\u001b[0;31m                                                  zero_division=zero_division)\n\u001b[0m\u001b[1;32m   1778\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1779\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1460\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"beta should be >=0 in the F-beta score\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1461\u001b[0m     labels = _check_set_wise_labels(y_true, y_pred, average, labels,\n\u001b[0;32m-> 1462\u001b[0;31m                                     pos_label)\n\u001b[0m\u001b[1;32m   1463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1464\u001b[0m     \u001b[0;31m# Calculate tp_sum, pred_sum, true_sum ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_set_wise_labels\u001b[0;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[1;32m   1272\u001b[0m                          str(average_options))\n\u001b[1;32m   1273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1274\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1275\u001b[0m     \u001b[0;31m# Convert to Python primitive type to avoid NumPy type / Python str\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1276\u001b[0m     \u001b[0;31m# comparison. See https://github.com/numpy/numpy/issues/6784\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     82\u001b[0m     \"\"\"\n\u001b[1;32m     83\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36mtype_of_target\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m    304\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m'continuous'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msuffix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m'multiclass'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msuffix\u001b[0m  \u001b[0;31m# [1, 2, 3] or [[1., 2., 3]] or [[1, 2]]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36munique\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/numpy/lib/arraysetops.py\u001b[0m in \u001b[0;36munique\u001b[0;34m(ar, return_index, return_inverse, return_counts, axis)\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0mar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_unique1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_inverse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_counts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    262\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_unpack_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/numpy/lib/arraysetops.py\u001b[0m in \u001b[0;36m_unique1d\u001b[0;34m(ar, return_index, return_inverse, return_counts)\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0maux\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mar\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mperm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 322\u001b[0;31m         \u001b[0mar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m         \u001b[0maux\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m     \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maux\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: '<' not supported between instances of 'float' and 'str'"
     ]
    }
   ],
   "source": [
    "k_fold_validator(predictor=X, target=y, vectorizer=countvec, classifier=nb_count, cv=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidfvec = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "k_fold_validator(predictor=X, target=y, vectorizer=tfidfvec, classifier=nb_count, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_stop = CountVectorizer(stop_words=stopwords_list_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_stop_max = CountVectorizer(stop_words=stopwords_list_2, max_features=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_stop_max_ngram = CountVectorizer(stop_words=stopwords_list_2, max_features=3000, ngram_range=(1, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_stop_ngram = CountVectorizer(stop_words=stopwords_list_2, ngram_range=(1, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "k_fold_validator(predictor=X, target=y, vectorizer=cv_stop, classifier=nb_count, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compnb = ComplementNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "k_fold_validator(predictor=X, target=y, vectorizer=countvec, classifier=compnb, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "k_fold_validator(predictor=X, target=y, vectorizer=cv_stop, classifier=compnb, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# max features improves recall\n",
    "\n",
    "k_fold_validator(predictor=X, target=y, vectorizer=cv_stop_max, classifier=compnb, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ngrams improve recall\n",
    "k_fold_validator(predictor=X_train, target=y_train, vectorizer=cv_stop_max_ngram, classifier=compnb, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#ngrams don't improve recall without max\n",
    "k_fold_validator(predictor=X_train, target=y_train, vectorizer=cv_stop_ngram, classifier=compnb, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_list_3 = ['sxsw', 'mention', 'rt']\n",
    "# same as 2 - can't improve on 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate on cv_stop_max_ngram\n",
    "cv_stop_max_ngram_2 = CountVectorizer(stop_words=stopwords_list_3, max_features=2000, ngram_range=(1, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# max 2k is a little better than 3k and 1k\n",
    "# ngram range 3 is better than 2 and 4\n",
    "k_fold_validator(predictor=X_train, target=y_train, vectorizer=cv_stop_max_ngram_2, classifier=compnb, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with precision of 15%, you need to read through\n",
    "100/15\n",
    "# 7 tweets to find a negative one\n",
    "# 22% of negative tweets are missed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you have to read through 17 tweets to find a negative one\n",
    "100/6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you get through your work 2 or 3 times as fast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use glove\n",
    "# create total vocabulary\n",
    "X_train_tokens = X_train.map(lambda x: word_tokenize(x))\n",
    "total_vocabulary = set(word for tweet in X_train_tokens for word in tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(total_vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from Codealong\n",
    "\n",
    "glove = {}\n",
    "with open('glove.6B.50d.txt', 'rb') as f:\n",
    "    for line in f:\n",
    "        parts = line.split()\n",
    "        word = parts[0].decode('utf-8')\n",
    "        if word in total_vocabulary:\n",
    "            vector = np.array(parts[1:], dtype=np.float32)\n",
    "            glove[word] = vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove['apple']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from Codealong\n",
    "\n",
    "class W2vVectorizer(object):\n",
    "    \n",
    "    def __init__(self, w2v):\n",
    "        # Takes in a dictionary of words and vectors as input\n",
    "        self.w2v = w2v\n",
    "        if len(w2v) == 0:\n",
    "            self.dimensions = 0\n",
    "        else:\n",
    "            self.dimensions = len(w2v[next(iter(glove))])\n",
    "    \n",
    "    # Note: Even though it doesn't do anything, it's required that this object implement a fit method or else\n",
    "    # it can't be used in a scikit-learn pipeline  \n",
    "    def fit(self, X, y):\n",
    "        return self\n",
    "\n",
    "    # added this method to work more easily with NLP_model_tester function\n",
    "    def fit_transform(self, X):\n",
    "        return np.array([\n",
    "            np.mean([self.w2v[w] for w in words if w in self.w2v]\n",
    "                   or [np.zeros(self.dimensions)], axis=0) for words in X])\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return np.array([\n",
    "            np.mean([self.w2v[w] for w in words if w in self.w2v]\n",
    "                   or [np.zeros(self.dimensions)], axis=0) for words in X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_list = [\n",
    "           ('CountVectorizer', CountVectorizer()),\n",
    "           ('TfidfVectorizer', TfidfVectorizer()),\n",
    "           ('W2vVectorizer', W2vVectorizer(glove))]\n",
    "mod_list = [\n",
    "#            ('Multinomial Naive Bayes', MultinomialNB()),\n",
    "#            ('Guassian Naive Bayes', GaussianNB()),\n",
    "           ('Random Forest', RandomForestClassifier()),\n",
    "           ('Support Vector Machine', SVC()),\n",
    "           ('Logistic Regression', LogisticRegression())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NLP_model_tester(X, y, vectorizers, models):\n",
    "    \n",
    "    X_tra, X_tst, y_tra, y_tst = train_test_split(X, y, test_size=0.3)\n",
    "    \n",
    "    for v in vectorizers:\n",
    "        for m in models:\n",
    "            \n",
    "            X_vec_tra = v[1].fit_transform(X_tra)\n",
    "            X_vec_tst = v[1].transform(X_tst)\n",
    "            \n",
    "            model = m[1]\n",
    "            model.fit(X_vec_tra, y_tra)\n",
    "            \n",
    "            y_pred_tra = m[1].predict(X_vec_tra)\n",
    "            y_pred_tst = m[1].predict(X_vec_tst)\n",
    "            \n",
    "            print(v[0], '/', m[0], 'Train Recall:', round(recall_score(y_tra, y_pred_tra, pos_label='Negative emotion'), 2))\n",
    "            print(v[0], '/', m[0], 'Train Precision:', round(precision_score(y_tra, y_pred_tra, pos_label='Negative emotion'), 2))\n",
    "\n",
    "            plot_confusion_matrix(model, X_vec_tra, y_tra)\n",
    "            plt.title(v[0] + '/' + m[0] + ' Train set')\n",
    "\n",
    "            print(v[0], '/', m[0], 'Test Recall:', round(recall_score(y_tst, y_pred_tst, pos_label='Negative emotion'), 2))\n",
    "            print(v[0], '/', m[0], 'Test Precision:', round(precision_score(y_tst, y_pred_tst, pos_label='Negative emotion'), 2))\n",
    "\n",
    "            plot_confusion_matrix(model, X_vec_tst, y_tst)\n",
    "            plt.title(v[0] + '/' + m[0] + ' Test set')\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "NLP_model_tester(X_train, y_train, vec_list, mod_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "k_fold_validator(predictor=X_train, target=y_train, vectorizer=CountVectorizer(), classifier=RandomForestClassifier(), cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k-fold cv for logistic regression\n",
    "\n",
    "kf = KFold(n_splits=5)\n",
    "\n",
    "train_recall_scores = []\n",
    "train_precision_scores = []\n",
    "test_recall_scores = []\n",
    "test_precision_scores = []\n",
    "\n",
    "for train_index, test_index in kf.split(X_train):\n",
    "\n",
    "    X_tr, X_test = X[train_index].astype(str), X[test_index].astype(str)\n",
    "    y_tr, y_test = y[train_index].astype(str), y[test_index].astype(str)\n",
    "\n",
    "    vec = CountVectorizer()\n",
    "    \n",
    "    X_vec_tr = vec.fit_transform(X_tr)\n",
    "    X_vec_test = vec.transform(X_test)\n",
    "\n",
    "    clf = LogisticRegression()\n",
    "    clf.fit(X_vec_tr, y_tr)\n",
    "\n",
    "    y_pred_tr = clf.predict(X_vec_tr)\n",
    "    y_pred_test = clf.predict(X_vec_test)\n",
    "\n",
    "    train_recall_scores.append(recall_score(y_tr, y_pred_tr, pos_label='Negative emotion'))\n",
    "    train_precision_scores.append(precision_score(y_tr, y_pred_tr, pos_label='Negative emotion'))\n",
    "    test_recall_scores.append(recall_score(y_test, y_pred_test, pos_label='Negative emotion'))\n",
    "    test_precision_scores.append(precision_score(y_test, y_pred_test, pos_label='Negative emotion'))\n",
    "\n",
    "    plot_confusion_matrix(clf, X_vec_tr, y_tr)\n",
    "    plt.title('Train set')\n",
    "\n",
    "    plot_confusion_matrix(clf, X_vec_test, y_test)\n",
    "    plt.title('Test set')\n",
    "\n",
    "print('Vectorizer:', vec)\n",
    "print('Classifier:', clf)\n",
    "print('Cross-validation folds:', cv)\n",
    "print('Train mean recall:', pd.Series(train_recall_scores).mean())\n",
    "print('Train mean precision:', pd.Series(train_precision_scores).mean())\n",
    "print('Test mean recall:', pd.Series(test_recall_scores).mean())\n",
    "print('Test mean precision:', pd.Series(test_precision_scores).mean())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_fold_validator(predictor=X_train, \n",
    "                 target=y_train, \n",
    "                 vectorizer=CountVectorizer(), \n",
    "                 classifier=LogisticRegression(), \n",
    "                 cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k-fold cv for support vector machine\n",
    "\n",
    "kf = KFold(n_splits=5)\n",
    "\n",
    "train_recall_scores = []\n",
    "train_precision_scores = []\n",
    "test_recall_scores = []\n",
    "test_precision_scores = []\n",
    "\n",
    "for train_index, test_index in kf.split(X_train):\n",
    "\n",
    "    X_tr, X_test = X[train_index].astype(str), X[test_index].astype(str)\n",
    "    y_tr, y_test = y[train_index].astype(str), y[test_index].astype(str)\n",
    "\n",
    "    vec = CountVectorizer()\n",
    "    \n",
    "    X_vec_tr = vec.fit_transform(X_tr)\n",
    "    X_vec_test = vec.transform(X_test)\n",
    "\n",
    "    clf = SVC()\n",
    "    clf.fit(X_vec_tr, y_tr)\n",
    "\n",
    "    y_pred_tr = clf.predict(X_vec_tr)\n",
    "    y_pred_test = clf.predict(X_vec_test)\n",
    "\n",
    "    train_recall_scores.append(recall_score(y_tr, y_pred_tr, pos_label='Negative emotion'))\n",
    "    train_precision_scores.append(precision_score(y_tr, y_pred_tr, pos_label='Negative emotion'))\n",
    "    test_recall_scores.append(recall_score(y_test, y_pred_test, pos_label='Negative emotion'))\n",
    "    test_precision_scores.append(precision_score(y_test, y_pred_test, pos_label='Negative emotion'))\n",
    "\n",
    "    plot_confusion_matrix(clf, X_vec_tr, y_tr)\n",
    "    plt.title('Train set')\n",
    "\n",
    "    plot_confusion_matrix(clf, X_vec_test, y_test)\n",
    "    plt.title('Test set')\n",
    "\n",
    "print('Vectorizer:', vec)\n",
    "print('Classifier:', clf)\n",
    "print('Cross-validation folds:', cv)\n",
    "print('Train mean recall:', pd.Series(train_recall_scores).mean())\n",
    "print('Train mean precision:', pd.Series(train_precision_scores).mean())\n",
    "print('Test mean recall:', pd.Series(test_recall_scores).mean())\n",
    "print('Test mean precision:', pd.Series(test_precision_scores).mean())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_fold_validator(predictor=X_train, \n",
    "                 target=y_train, \n",
    "                 vectorizer=CountVectorizer(), \n",
    "                 classifier=SVC(), \n",
    "                 cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k-fold cv for random forest\n",
    "\n",
    "kf = KFold(n_splits=5)\n",
    "\n",
    "train_recall_scores = []\n",
    "train_precision_scores = []\n",
    "test_recall_scores = []\n",
    "test_precision_scores = []\n",
    "\n",
    "for train_index, test_index in kf.split(X_train):\n",
    "\n",
    "    X_tr, X_test = X[train_index].astype(str), X[test_index].astype(str)\n",
    "    y_tr, y_test = y[train_index].astype(str), y[test_index].astype(str)\n",
    "\n",
    "    vec = CountVectorizer()\n",
    "    \n",
    "    X_vec_tr = vec.fit_transform(X_tr)\n",
    "    X_vec_test = vec.transform(X_test)\n",
    "\n",
    "    clf = RandomForestClassifier()\n",
    "    clf.fit(X_vec_tr, y_tr)\n",
    "\n",
    "    y_pred_tr = clf.predict(X_vec_tr)\n",
    "    y_pred_test = clf.predict(X_vec_test)\n",
    "\n",
    "    train_recall_scores.append(recall_score(y_tr, y_pred_tr, pos_label='Negative emotion'))\n",
    "    train_precision_scores.append(precision_score(y_tr, y_pred_tr, pos_label='Negative emotion'))\n",
    "    test_recall_scores.append(recall_score(y_test, y_pred_test, pos_label='Negative emotion'))\n",
    "    test_precision_scores.append(precision_score(y_test, y_pred_test, pos_label='Negative emotion'))\n",
    "\n",
    "    plot_confusion_matrix(clf, X_vec_tr, y_tr)\n",
    "    plt.title('Train set')\n",
    "\n",
    "    plot_confusion_matrix(clf, X_vec_test, y_test)\n",
    "    plt.title('Test set')\n",
    "\n",
    "print('Vectorizer:', vec)\n",
    "print('Classifier:', clf)\n",
    "print('Cross-validation folds:', cv)\n",
    "print('Train mean recall:', pd.Series(train_recall_scores).mean())\n",
    "print('Train mean precision:', pd.Series(train_precision_scores).mean())\n",
    "print('Test mean recall:', pd.Series(test_recall_scores).mean())\n",
    "print('Test mean precision:', pd.Series(test_precision_scores).mean())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try a neural net\n",
    "\n",
    "one_hot_y = pd.get_dummies(y_train).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = text.Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "list_tokenized_tweets = tokenizer.texts_to_sequences(X_train)\n",
    "X_t = sequence.pad_sequences(list_tokenized_tweets, maxlen=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = Sequential()\n",
    "embedding_size = 128\n",
    "nn.add(Embedding(5000, embedding_size))\n",
    "nn.add(LSTM(25, return_sequences=True))\n",
    "nn.add(GlobalMaxPool1D())\n",
    "nn.add(Dropout(0.5))\n",
    "nn.add(Dense(50, activation='relu'))\n",
    "nn.add(Dropout(0.5))\n",
    "nn.add(Dense(2, activation='softmax'))\n",
    "\n",
    "nn.compile(loss='categorical_crossentropy', \n",
    "              optimizer='adam', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.fit(X_t, one_hot_y, epochs=10, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a df\n",
    "# pd.DataFrame(columns =)\n",
    "\n",
    "nn.predict(X_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
